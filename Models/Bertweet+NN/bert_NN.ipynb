{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch, csv, emoji\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sigmoid\n",
    "import torch.optim as optim\n",
    "from torchtext.data.metrics import bleu_score\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer \n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from Bert_NN import read_csv, vectorize_sentences, convert_str, emojiDataset, toEmoji\n",
    "from utils import DATAPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = open('log.txt', 'w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------Begining Data Loading-----------------------\n",
      "\n",
      "Loading data for file '01'.\n",
      "Loaded 240 labelled sentence and emoji data.\n",
      "\n",
      "Loading data for file '02'.\n",
      "Loaded 227 labelled sentence and emoji data.\n",
      "\n",
      "Loading data for file '03'.\n",
      "Loaded 247 labelled sentence and emoji data.\n",
      "\n",
      "Loading data for file '04'.\n",
      "Loaded 248 labelled sentence and emoji data.\n",
      "\n",
      "Loading data for file '05'.\n",
      "Loaded 205 labelled sentence and emoji data.\n",
      "\n",
      "Loaded total 1167 labelled sentence and emoji data in 0.0 minutes.\n",
      "\n",
      "-----------------------Finished Data Loading-----------------------\n",
      "\n",
      "\n",
      "-----------------------Begining Feature Extraction-----------------------\n",
      "Extracted total 1167 feature and label data in 0.9 minutes.\n",
      "\n",
      "-----------------------Finished Feature Extraction-----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features, labels, total, sentences, emojis, labels_classes = vectorize_sentences(DATAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.BCELoss()\n",
    "S = Sigmoid()\n",
    "epochs = 10\n",
    "num_folds = 5\n",
    "cross_validation = model_selection.KFold(n_splits=num_folds, random_state=None, shuffle=True)\n",
    "\n",
    "bleu_max_n = 1\n",
    "bleu_weights = [1]\n",
    "\n",
    "best_to_emoji = None\n",
    "best_score = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 0/5\n",
      "\n",
      "Fold: 0/5 with Average BLEU Score : 0.0\n",
      "\n",
      "Fold: 1/5\n",
      "\n",
      "Fold: 1/5 with Average BLEU Score : 0.0\n",
      "\n",
      "Fold: 2/5\n",
      "\n",
      "Fold: 2/5 with Average BLEU Score : 0.0\n",
      "\n",
      "Fold: 3/5\n",
      "\n",
      "Fold: 3/5 with Average BLEU Score : 0.0\n",
      "\n",
      "Fold: 4/5\n",
      "\n",
      "Fold: 4/5 with Average BLEU Score : 0.0\n"
     ]
    }
   ],
   "source": [
    "for index, (train_index, test_index) in enumerate(cross_validation.split(features)):\n",
    "    print(f'\\nFold: {index+1}/{num_folds}')\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "    train_dataset = emojiDataset(features_train, labels_train)\n",
    "    data_loader = DataLoader(dataset=train_dataset, batch_size=32)\n",
    "\n",
    "    toemoji = toEmoji()\n",
    "    learn_rate = optim.Adam(toemoji.parameters(), lr=0.005)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # print(f'\\tEpoch: {i+1}/{epochs}')\n",
    "        for data in data_loader:\n",
    "            cur_train_features, cur_train_labels = data\n",
    "            toemoji.zero_grad()\n",
    "            results = toemoji(cur_train_features.float())\n",
    "            S_results = S(results)\n",
    "            loss = loss_func(S_results, cur_train_labels)\n",
    "            loss.backward()\n",
    "            learn_rate.step()\n",
    "        # print('\\t\\tloss is: {:.4f}'.format(loss))\n",
    "    \n",
    "    test_dataset = emojiDataset(features_test, labels_test)\n",
    "    data_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)\n",
    "    total_BLEU = 0\n",
    "    for data in data_loader:\n",
    "        cur_test_features, cur_test_labels = data\n",
    "        toemoji.zero_grad()\n",
    "        results = toemoji(cur_test_features.float())\n",
    "        result_labels = []\n",
    "        for result_index, result in enumerate(results) :\n",
    "            result_labels.append(['1' if elem.item()>0 else '0' for elem in result])        \n",
    "        total_BLEU += bleu_score(convert_str(cur_test_labels), result_labels, max_n=bleu_max_n, weights=bleu_weights)\n",
    "    average_BLUE = total_BLEU/len(data_loader)\n",
    "    print(f'\\nFold: {index+1}/{num_folds} with Average BLEU Score : {average_BLUE}')\n",
    "    if average_BLUE > best_score: best_to_emoji = toemoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c4da39f60e9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoemoji\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mcur_BLEU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moriginal_label_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchtext\\data\\metrics.py\u001b[0m in \u001b[0;36mbleu_score\u001b[1;34m(candidate_corpus, references_corpus, max_n, weights)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_corpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreferences_corpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mcandidate_len\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# Get the length of the reference that's closest in length to the candidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"len() of a 0-d tensor\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m             warnings.warn('Using len to get tensor shape might cause the trace to be incorrect. '\n",
      "\u001b[1;31mTypeError\u001b[0m: len() of a 0-d tensor"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "collection = defaultdict(int)\n",
    "predicted = defaultdict(int)\n",
    "\n",
    "total_dataset = emojiDataset(features, labels)\n",
    "data_loader = DataLoader(dataset=total_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(total_dataset) :\n",
    "        feature, label = data\n",
    "        result = toemoji(feature.float())\n",
    "        cur_BLEU = bleu_score(result, label)\n",
    "        result = [index for index, elem in enumerate(result) if elem.item()>0]\n",
    "        original_label_index = [index for index, elem in enumerate(label) if elem!=0]\n",
    "        # print(original_label_index)\n",
    "        for label_index in result:\n",
    "            predicted[label_index] += 1\n",
    "        for label_index in original_label_index:\n",
    "            collection[label_index] += 1\n",
    "        \n",
    "        real_labels = [labels_classes[label_index] for label_index in result]\n",
    "\n",
    "        print(f'Sentence: {sentences[i]} with Bleu score: {cur_BLEU}\\nOriginal labels: {emojis[i]}, output labels: {real_labels}\\n') \n",
    "\n",
    "for index, label in enumerate(labels_classes):\n",
    "    print(f'Emoji: {label} has count: {collection[index]} predicted times: {predicted[index]}')\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51b98c02896680ea37226d8daf7bb7567da480dbab6550fb190a6d80b8c8d38f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
