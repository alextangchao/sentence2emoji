{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch, csv, emoji\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from NN import FILEPATH, read_csv, emojiDataset, toEmoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = read_csv(FILEPATH)\n",
    "print(a[0][-1], a[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = emojiDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=dataset, batch_size=16, shuffle=True,num_workers=2)\n",
    "sentences, emojis, labels_classes = dataset.get_others()\n",
    "\n",
    "# data_iter = iter(data_loader)\n",
    "# next_data = data_iter.next()\n",
    "# features, labels = next_data\n",
    "# print(features, labels)\n",
    "\n",
    "toemoji = toEmoji()\n",
    "learn_rate = optim.Adam(toemoji.parameters(), lr=0.005)\n",
    "loss_func = nn.MSELoss()\n",
    "# loss_func = nn.NLLLoss()\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    for data in data_loader:\n",
    "        features, labels = data\n",
    "        toemoji.zero_grad()\n",
    "        results = toemoji(features.float())\n",
    "        # print(result)\n",
    "        # print(results, labels)\n",
    "        loss = loss_func(results, labels)\n",
    "        # for result, label in zip(results, labels):\n",
    "        #     loss += F.nll_loss(result, label) \n",
    "        loss.backward()\n",
    "        learn_rate.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(sentences)) :\n",
    "        feature, label = dataset[i]\n",
    "        result = toemoji(feature.float())\n",
    "        print(f'Sentence: {sentences[i]}\\nOriginal labels: {emojis[i][0]}, output labels: {result[0]}\\n') \n",
    "        # original_str, result_str = '', ''\n",
    "\n",
    "        # top_k = (-result).argsort()[:K]\n",
    "        # for top_index in top_k:\n",
    "        #     result_str += labels_classes[top_index]\n",
    "        \n",
    "        # original_str = ''.join(emojis[i])\n",
    "        \n",
    "        # print(f'Sentence: {sentences[i]}\\nOriginal labels: {original_str}, output labels: {result_str}\\n')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51b98c02896680ea37226d8daf7bb7567da480dbab6550fb190a6d80b8c8d38f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
